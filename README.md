# Adversarial facial accessory presentation attacks (PAs) database

## Introduction

The adversarial facial accessory presentation attacks database (henceforth, ''database'') contains images used for the detection of adversarial facial accessory presentation attacks. To foster the research of face presentation attack detection, the database will be released to researchers for academic research purpose upon request.

The database is summarized below.

| Entries                         | Descriptions                                                                          |
| ---                             |---                                                                                    |
| number of data subjects         | 101 (59 males, 42 females), 39 for training and 62 for testing                        |
| training set                    | 3900 bona fide face images, 3900 presentation attack images                           |
| testing set                     | 3300 bona fide face images, 5150 presentation attack images                           |
| adversarial examples            | generated by the methods in [1] and [2]                                               |
| presentation attack instruments | eyeglasses, masks, hats, and stickers                                                 |
| illumination conditions         | indoor and outdoor illumination conditions                                            |
| cameras                         | Canon EOS 600D and smartphones of the data subjects                                   |

Some images of the database are shown below, the black boxes are used for privacy concerns but are not used in the experiments. (a) Bona fide face image. (b) Image of eyeglasses PA generated by [1]. (c) Image of mask PA. (d) Image of hat PA. (e) Image of sticker PA. (f) Image of eyeglasses PA generated by [2]. (g) Reference face image.

<div align="center">
  <img src="https://github.com/pp21/advfapadb/blob/main/images.jpg">
</div>

## Testing protocols

The database contains 5 testing protocols with the the variations of adversarial example generation methods, presentation attack instruments (PAIs), illumination conditions, and cameras. The testing protocols are listed below.

| Testing protocols | Training set                            |  Testing set                          |
| ---               | ---                                     | ---                                   |
| protocol 1        | all the training images                 | all the testing images                |
| protocol 2        | images of 1 type of adversarial example | images of unseen adversarial examples |
| protocol 3        | images of 1 PAI or 3 PAIs               | images of unseen PAIs                 |
| protocol 4        | images of indoor illumination           | images of outdoor illumination        |
| protocol 5        | images captured by Canon EOS 600D       | images captured by smartphones        |

## How to get access to the database?

If you are interested in the database, please read the [database release agreement](https://github.com/pp21/advfapadb/blob/main/agreement.pdf) and send your request to the corresponding author of the database. Thank you.

## References

[1] 
```
@inproceedings{Sharif16AdvML,
  author =       {Mahmood Sharif and Sruti Bhagavatula and Lujo Bauer 
						and Michael K. Reiter},
  title =        {Accessorize to a crime: {R}eal and stealthy attacks 
  						on state-of-the-art face recognition},
  booktitle =    {Proceedings of the 23rd ACM SIGSAC Conference on 
						Computer and Communications Security},
  year =         2016
} 
```
[2]
```
@article{Sharif19AGNs,
  author =       {Mahmood Sharif and Sruti Bhagavatula and 
  					  Lujo Bauer and Michael K. Reiter},
  title =        {A general framework for adversarial examples 
  					  with objectives},
  journal =      {ACM Transactions on Privacy and Security},
  year =         2019
}
```
